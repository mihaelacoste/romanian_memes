{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33364a5c-2d6f-4e1e-bf1f-504e8c63be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2e04b-e203-45d2-b20d-7cbf48918e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas requests openpyxl # openpyxl is needed for Excel output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0449131-03fb-45ba-9798-f737d8e722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# --- Reddit API Credentials ---\n",
    "# IMPORTANT: Replace with your actual credentials.\n",
    "CLIENT_ID = \"enter_client_id_here\"\n",
    "CLIENT_SECRET = \"enter_client_secret_here\"\n",
    "USER_AGENT = \"MyRomemesScraper by /u/Objective_Team621 v1.0\" # Replace with your Reddit username\n",
    "USERNAME = \"enter_reddit_username\" # Your Reddit username\n",
    "PASSWORD = \"enter_reddit_pass\" # Your Reddit password\n",
    "\n",
    "# --- Configuration ---\n",
    "SUBREDDIT_NAME = \"romemes\"\n",
    "TARGET_DATE = datetime.datetime(2025, 5, 1, 0, 0, 0, tzinfo=datetime.timezone.utc) # May 1st, 2025, 00:00:00 UTC\n",
    "FETCH_LIMIT = 1000 # Set to None for unlimited, or a number for testing. Be mindful of rate limits.\n",
    "\n",
    "OUTPUT_CSV_FILE = \"romemes_posts.csv\"\n",
    "OUTPUT_EXCEL_FILE = \"romemes_posts.xlsx\"\n",
    "DOWNLOAD_FOLDER = \"romemes_downloads\" # Folder to save images/media\n",
    "\n",
    "def get_posts_after_date(subreddit_name, target_date, fetch_limit=None):\n",
    "    \"\"\"\n",
    "    Connects to Reddit API, fetches new posts from a subreddit,\n",
    "    and returns those created after the target_date.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=CLIENT_ID,\n",
    "            client_secret=CLIENT_SECRET,\n",
    "            user_agent=USER_AGENT,\n",
    "            username=USERNAME,\n",
    "            password=PASSWORD\n",
    "        )\n",
    "        print(f\"Successfully connected to Reddit as {reddit.user.me()} (read_only: {reddit.read_only})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Reddit: {e}\")\n",
    "        print(\"Please check your API credentials and ensure your Reddit account is active.\")\n",
    "        return []\n",
    "\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts_data = []\n",
    "\n",
    "    print(f\"\\nFetching posts from r/{subreddit_name} after {target_date.strftime('%Y-%m-%d %H:%M:%S UTC')}...\")\n",
    "\n",
    "    # Iterate through new submissions\n",
    "    for submission in subreddit.new(limit=fetch_limit):\n",
    "        post_created_utc = datetime.datetime.fromtimestamp(submission.created_utc, tz=datetime.timezone.utc)\n",
    "\n",
    "        if post_created_utc > target_date:\n",
    "            # Generate a unique ID (Unix timestamp + submission ID)\n",
    "            unique_id = f\"{int(submission.created_utc)}_{submission.id}\"\n",
    "            \n",
    "            posts_data.append({\n",
    "                \"id\": unique_id, # Unique identifier\n",
    "                \"title\": submission.title,\n",
    "                \"author\": submission.author.name if submission.author else \"[deleted]\",\n",
    "                \"score\": submission.score,\n",
    "                \"num_comments\": submission.num_comments,\n",
    "                \"created_utc\": post_created_utc.strftime('%Y-%m-%d %H:%M:%S UTC'),\n",
    "                \"url\": submission.url,\n",
    "                \"permalink\": f\"https://reddit.com{submission.permalink}\",\n",
    "                \"is_self\": submission.is_self, # True if text post, False if link/image/video\n",
    "                \"media_url\": submission.url if not submission.is_self else None # URL to download\n",
    "            })\n",
    "        else:\n",
    "            # Since .new() returns posts by most recent, if we find a post\n",
    "            # that's older than our target date, we can stop searching.\n",
    "            print(f\"Stopping search: encountered post older than target date (Post ID: {submission.id}, Created: {post_created_utc})\")\n",
    "            break\n",
    "\n",
    "        time.sleep(0.1) # Small delay for politeness\n",
    "\n",
    "    return posts_data\n",
    "\n",
    "def download_media(posts, download_folder):\n",
    "    \"\"\"\n",
    "    Downloads media from post URLs to the specified folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "        print(f\"Created download folder: {download_folder}\")\n",
    "\n",
    "    print(f\"\\nAttempting to download media to '{download_folder}'...\")\n",
    "    downloaded_count = 0\n",
    "\n",
    "    for post in posts:\n",
    "        media_url = post.get(\"media_url\")\n",
    "        post_id = post.get(\"id\")\n",
    "        post_title = post.get(\"title\", \"untitled_post\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\") # Sanitize title for filename\n",
    "        \n",
    "        if media_url and not post.get(\"is_self\"): # Only download if it's a link post (not a text post)\n",
    "            try:\n",
    "                # Get file extension from the URL\n",
    "                file_extension = os.path.splitext(media_url)[1].split(\"?\")[0] # handle query parameters\n",
    "                if not file_extension: # Fallback for URLs without explicit extensions, e.g., imgur links without .jpg\n",
    "                    # Try to infer from content type or use a common default\n",
    "                    response_head = requests.head(media_url, allow_redirects=True, timeout=5)\n",
    "                    content_type = response_head.headers.get('content-type')\n",
    "                    if content_type and 'image' in content_type:\n",
    "                        if 'jpeg' in content_type: file_extension = '.jpeg'\n",
    "                        elif 'png' in content_type: file_extension = '.png'\n",
    "                        elif 'gif' in content_type: file_extension = '.gif'\n",
    "                        # Add other types as needed\n",
    "                    else:\n",
    "                        print(f\"  Skipping: Could not determine file type for {media_url}\")\n",
    "                        continue\n",
    "                \n",
    "                # Create a sanitized filename based on title or ID\n",
    "                # Limit title length for filename to avoid OS issues\n",
    "                sanitized_title = post_title[:50] if len(post_title) > 50 else post_title\n",
    "                filename = f\"{post_id}_{sanitized_title}{file_extension}\"\n",
    "                filepath = os.path.join(download_folder, filename)\n",
    "\n",
    "                print(f\"  Downloading: {media_url} to {filepath}\")\n",
    "                response = requests.get(media_url, stream=True, timeout=10)\n",
    "                response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                downloaded_count += 1\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"  Error downloading {media_url} (Post ID: {post_id}): {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  An unexpected error occurred for {media_url} (Post ID: {post_id}): {e}\")\n",
    "        elif post.get(\"is_self\"):\n",
    "            print(f\"  Skipping text post: {post_title} (ID: {post_id})\")\n",
    "        else:\n",
    "            print(f\"  Skipping: No media URL found for {post_title} (ID: {post_id})\")\n",
    "            \n",
    "    print(f\"\\nFinished downloading. {downloaded_count} media files successfully downloaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    posts_data = get_posts_after_date(SUBREDDIT_NAME, TARGET_DATE, fetch_limit=FETCH_LIMIT)\n",
    "\n",
    "    if posts_data:\n",
    "        # 1. Create CSV/Excel output\n",
    "        print(f\"\\nFound {len(posts_data)} posts. Creating CSV and Excel files...\")\n",
    "        df = pd.DataFrame(posts_data)\n",
    "        \n",
    "        # Select and reorder columns for clarity in output files\n",
    "        output_df = df[[\n",
    "            \"id\",\n",
    "            \"title\",\n",
    "            \"author\",\n",
    "            \"score\",\n",
    "            \"num_comments\",\n",
    "            \"created_utc\",\n",
    "            \"url\",\n",
    "            \"permalink\"\n",
    "        ]]\n",
    "\n",
    "        output_df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8')\n",
    "        print(f\"Data saved to {OUTPUT_CSV_FILE}\")\n",
    "\n",
    "        output_df.to_excel(OUTPUT_EXCEL_FILE, index=False)\n",
    "        print(f\"Data saved to {OUTPUT_EXCEL_FILE}\")\n",
    "\n",
    "        # 2. Download media\n",
    "        download_media(posts_data, DOWNLOAD_FOLDER)\n",
    "    else:\n",
    "        print(f\"No posts found in r/{SUBREDDIT_NAME} after {TARGET_DATE.strftime('%Y-%m-%d %H:%M:%S UTC')} within the fetched limit.\")\n",
    "        print(\"Please check your API credentials and the subreddit activity for the specified date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e8c49-8c76-4ab2-bedf-e3db47edbebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
